{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group DARK Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import re\n",
    "import xml.etree.ElementTree as etree\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup()\n",
    "path_list = glob.glob('data/*.xml')\n",
    "\n",
    "data_dicts = []\n",
    "for f in path_list:\n",
    "    \n",
    "     \n",
    "    soup = BeautifulSoup(open(f), 'html.parser') # I had to use html in order to extract the CData from the XML\n",
    "\n",
    "    #find the text of the note, which is stored in the CData \n",
    "    text = soup.find(text=lambda text: isinstance(text, bs4.CData)).string.strip()\n",
    "\n",
    "    \n",
    "    #use regular expression to clean the notes \n",
    "    text = re.sub(r'\\n+', ' ', text) #remove new paragraph \n",
    "    text = re.sub(r'\\s\\s+\\s*', '', text) #remove multiple spaces\n",
    "    text = re.sub(r'\\_+', '', text) #remove underline\n",
    "    \n",
    "    #gather smoker status\n",
    "    try:\n",
    "        smoker = soup.find('smoker').get('status') #find the smoker status\n",
    "    except AttributeError:\n",
    "        smoker = 'unknown'\n",
    "   \n",
    "    #find the status of coronary artery disease, 'unknown' will be stored if not known\n",
    "    try:\n",
    "        CAD = soup.find('cad').get('indicator')\n",
    "        \n",
    "    except AttributeError: \n",
    "        \n",
    "        CAD = 'unknown'\n",
    "    \n",
    "    data_dicts.append({'Note': text, 'Smoker': smoker, 'CAD': CAD, 'File name': f})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data_dicts)\n",
    "df = df.drop_duplicates() #in case some files get passed mulitple times, we'll delete any duplicates\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Note</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>CAD</th>\n",
       "      <th>File name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2093-04-28BMC EMERGENCY DEPT VISI...</td>\n",
       "      <td>past</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/379-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Record date: 2093-01-13 Team X Intern Admissio...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>data/279-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Record date: 2088-05-21 Patient Name: CURTIS, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/119-01.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Record date: 2062-03-27 Hematology Clinic Prog...</td>\n",
       "      <td>never</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/304-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Record date: 2135-12-15CARDIOLOGYPERDUE MEDICA...</td>\n",
       "      <td>past</td>\n",
       "      <td>test</td>\n",
       "      <td>data/204-03.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Note   Smoker      CAD  \\\n",
       "0  Record date: 2093-04-28BMC EMERGENCY DEPT VISI...     past  unknown   \n",
       "1  Record date: 2093-01-13 Team X Intern Admissio...  unknown     test   \n",
       "2  Record date: 2088-05-21 Patient Name: CURTIS, ...  unknown  unknown   \n",
       "3  Record date: 2062-03-27 Hematology Clinic Prog...    never  unknown   \n",
       "4  Record date: 2135-12-15CARDIOLOGYPERDUE MEDICA...     past     test   \n",
       "\n",
       "         File name  \n",
       "0  data/379-03.xml  \n",
       "1  data/279-03.xml  \n",
       "2  data/119-01.xml  \n",
       "3  data/304-03.xml  \n",
       "4  data/204-03.xml  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1304 entries, 0 to 1303\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Note       1304 non-null   object\n",
      " 1   Smoker     1304 non-null   object\n",
      " 2   CAD        1304 non-null   object\n",
      " 3   File name  1304 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 50.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Record date: 2148-07-28 Internal Medicine Intern Admit Note Pt: Samuel Tuttle MR: 2793372 Cc: EKG changesHPI: 66 y.o. male with pmhx of DM, incr.cholestoral, and autonomic insufficeny admitted for EKG changes. The patient has significant risk factors for CAD of DM, incr. Cholesterol, and h/o htn.He had a adenosine stress test done in 11/47 which was negative for ischemia (lasting 5min and PDP of 13746). His last echo was done in 4/48 showed an EF of 59% presented to the health clinic with a 3 day hx of worsening L shoulder pain and episodes of diaphoresis. The shoulder pain is chronic and thought to be due to oa, and dm chor.He came to the clinic today for a BP check ( he is often hypotensive and orthostatic) and was noted to have TWI inferiorly and laterally on routine EKG.He denied any chest pain, nausea, vomiting when he went to the e.r.In the e.r., his first set of cardiac enzymes was negative, he was also started on heparin IV, and given IV lopressor, and an aspirin. Of note, the patient had a bp up to 182/88. When the patient arrived on the floor he denied any chest pain, nausea, vomiting, diaphoresis. His BP was noted to be 228/105. 2.5 IV lopressor, 12.5 PO lopressor, and nitropaste were given initially to lower bp to 170/75. PMHx DM (hx of diabetic retinopathy, nephropathy, autonomic instability, neuropathy) Hypercholesterolemia Autonomic insufficiency Polyneuropathy TB Asbestos CRI (baseline 2.1) Depression Arthritis (chronic left shoulder pain) Medications: Lovastatin 40mg QD ASA 81mg QD Insulin 75/25 22qam 24qpm Prilosec 20 mg qd Proamatine 10mg TID Florinef 0.2mg qd Ultram 37.5mg TID Celexa 60mg QD Buspar 10mg QD Allergies:NKDA SOCIAL HISTORY:Lives with his wife.He used to work at foxworthy industrials in2100-2104, after which he had industrial exposure to various chemicals suchas trichloroethylene, asbestos and incinerator smoke.He retired in 2141. :Smoking: 30 pack year smoking history, quit in 2107.Alcohol:heavy drinking for 40 years, cut down in 2146 and has stopped drinkingsince December, 2146.Denies any drug use. P/E: BP226/109 T96.6 P74 R20 O2 98% on 2L GEN: WDWN male in n.a.d. HEENT: EOMI, PERRL, no o-p erythema, no carotid bruits, JVP not visible with patient sitting upright Chest: crackles Left lung base,good air movement bilaterally C-V: regular, s1 s2 no m/g/r PMI in 5th intercostals space midclavicular line Abd: soft nt normoactive bs Ext: skin changes on anterior legs bilaterally in LE. No edema Neuro: A&O x3. CN II-XII intact. No focal motor or sensory deficits Labs: 7.2>33.1<214 PT 12.8 PTT22.8 Na -146. K 3.8, Cl 113, CO2 24.4, BUN 32, Cr 2.2, Gluc 148 Mg 1.7 PO4 3.2 Ca 9.7 Alb 4, direct bili .6, Alk phos 82, AST 32, ALT 37 CK IE negative, Troponin negative Chest x-ray -1.NO EVIDENCE OF PNEUMONIA OR PULMONARY EDEMA.2.CALCIFIED PLEURAL PLAQUES, AS BEFORE.3.A NODULAR OPACITY IN THE RIGHT UPPER LUNG ZONE IS NOW BETTERDEFINED THAN IN THE PREVIOUS EXAMINATION.IN LIGHT OF THE CHANGEIN APPEARANCE, CHEST C. T. MAY BE WARRANTED TO EXCLUDE A GROWINGNEOPLASM. EKG- from e.r. TWI in II, III, avF, v3-v6. borderline LVH, left atrial enlargement On admission - flattened TW in II, II,avF, TWI v4, v5 Imp: 66 y.o. male with hx of DM, autonomic instability, incr. Cholesterol presents with new EKG changes. Plan: 1.C-V a)\\tischemia - r/o MI, first set of cardiac enzymes negative, will get two more sets to r/o. Will monitor for EKG changes. New TWI in inferior and lateral chest leads worrisome in a patient with multiple risk factors. Last stress negative 6 months ago. Will talk with PCP and team in a.m. to discuss the need for stress in asymptomatic patient with recent stress. EKG changes may be secondary to htn strain. Will d/c IV heparin. Cont. po lopressor as long as patient's bp tolerates it. ASA qd. Appreciate input of Dr. Bodnari and will discuss future management. b)\\tPump - last ef 59% pt. Appears euvolemic c)\\tRhythm - no hx of arrythmia, on cardiac monitor/telemetry overnight 2. HTN - pt. Htn when he arrived on floor. Hx of hypotension. Will give low dose lopressor 12.5mg BID as well as nitropaste. Need to be careful of lowering BP too fast. Pt.'s bp unstable in past.Will hold florinef and proamatine for now 3. DM - hx of retinopathy, nephropathy, and neuropathy. Will maintain on home regiman of nph, and cover with iss. 4. Shoulder pain - ultram, PT5. Resp - opacity in RUL, may be secondary to old TB. According to radiologist reading it has changed since past x-rays. Asymptomatic. Can be worked up as an outpatient. 6. Prophylaxis - pneumoboots, nexium  Bobby U. Spears, M.D.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[20]['Note'] #display an example note from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    635\n",
       "never      304\n",
       "past       262\n",
       "current     91\n",
       "ever        12\n",
       "Name: Smoker, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming, 'ever' was a typo of 'never'\n",
    "df['Smoker'] = df['Smoker'].replace({'ever': 'never'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    635\n",
       "never      316\n",
       "past       262\n",
       "current     91\n",
       "Name: Smoker, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Smoker'].value_counts() #verify the change took place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    734\n",
       "mention    337\n",
       "test        91\n",
       "event       83\n",
       "symptom     59\n",
       "Name: CAD, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    635\n",
       "never      316\n",
       "past       262\n",
       "current     91\n",
       "Name: Smoker, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Note</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>CAD</th>\n",
       "      <th>File name</th>\n",
       "      <th>binary smoker</th>\n",
       "      <th>binary CAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Record date: 2093-04-28BMC EMERGENCY DEPT VISI...</td>\n",
       "      <td>past</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/379-03.xml</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Record date: 2093-01-13 Team X Intern Admissio...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>data/279-03.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Record date: 2088-05-21 Patient Name: CURTIS, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/119-01.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Record date: 2062-03-27 Hematology Clinic Prog...</td>\n",
       "      <td>never</td>\n",
       "      <td>unknown</td>\n",
       "      <td>data/304-03.xml</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Record date: 2135-12-15CARDIOLOGYPERDUE MEDICA...</td>\n",
       "      <td>past</td>\n",
       "      <td>test</td>\n",
       "      <td>data/204-03.xml</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Note   Smoker  \\\n",
       "0           0  Record date: 2093-04-28BMC EMERGENCY DEPT VISI...     past   \n",
       "1           1  Record date: 2093-01-13 Team X Intern Admissio...  unknown   \n",
       "2           2  Record date: 2088-05-21 Patient Name: CURTIS, ...  unknown   \n",
       "3           3  Record date: 2062-03-27 Hematology Clinic Prog...    never   \n",
       "4           4  Record date: 2135-12-15CARDIOLOGYPERDUE MEDICA...     past   \n",
       "\n",
       "       CAD        File name  binary smoker  binary CAD  \n",
       "0  unknown  data/379-03.xml            1.0           0  \n",
       "1     test  data/279-03.xml            NaN           1  \n",
       "2  unknown  data/119-01.xml            NaN           0  \n",
       "3  unknown  data/304-03.xml            0.0           0  \n",
       "4     test  data/204-03.xml            1.0           1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create binary classifications for smoker and CAD \n",
    "\n",
    "#since we don't know if 'unknown' means non-smoker, we will drop it from the dataset\n",
    "smoker_replacements = {'unknown': np.nan, 'never': 0, 'past': 1, 'current': 1}\n",
    "\n",
    "#for CAD, we will assume 'unknown' to be someone for which there's no reason to assume coronary artery disease\n",
    "def binary(row):\n",
    "    if row == 'unknown':\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "df['binary smoker'] = df['Smoker'].replace(smoker_replacements)\n",
    "\n",
    "df['binary CAD'] = df['CAD'].apply(binary)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df to csv to make re-running easier\n",
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data back in\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 669 entries, 0 to 1303\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Note           669 non-null    object \n",
      " 1   binary smoker  669 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# since this project will require training two neural networks, and we have to drop some values for the smoker model, \n",
    "#we will split them into two seperate datasets. \n",
    "\n",
    "df_smoker = df[['Note', 'binary smoker']].dropna()\n",
    "\n",
    "df_smoker.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1304 entries, 0 to 1303\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Note        1304 non-null   object\n",
      " 1   binary CAD  1304 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 20.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_CAD = df[['Note', 'binary CAD']]\n",
    "df_CAD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages for the tensorflow model\n",
    "# !pip install -q tensorflow-hub\n",
    "# !pip install -q tfds-nightly\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C = df_CAD['Note']\n",
    "y_C = df_CAD['binary CAD']\n",
    "\n",
    "X_S = df_smoker['Note']\n",
    "y_S = df_smoker['binary smoker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split both of the datasets into testing and training\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = train_test_split(X_C, y_C, random_state=42, test_size=.2)\n",
    "\n",
    "X_train_S, X_test_S, y_train_S, y_test_S = train_test_split(X_S, y_S, random_state=42, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1043 samples, validate on 261 samples\n",
      "Epoch 1/30\n",
      "1043/1043 [==============================] - 1s 931us/sample - loss: 0.8464 - accuracy: 0.5561 - val_loss: 0.6868 - val_accuracy: 0.5977\n",
      "Epoch 2/30\n",
      "1043/1043 [==============================] - 0s 428us/sample - loss: 0.7177 - accuracy: 0.5657 - val_loss: 0.6742 - val_accuracy: 0.5977\n",
      "Epoch 3/30\n",
      "1043/1043 [==============================] - 0s 405us/sample - loss: 0.6921 - accuracy: 0.5724 - val_loss: 0.6689 - val_accuracy: 0.5977\n",
      "Epoch 4/30\n",
      "1043/1043 [==============================] - 0s 379us/sample - loss: 0.6729 - accuracy: 0.5781 - val_loss: 0.6636 - val_accuracy: 0.5939\n",
      "Epoch 5/30\n",
      "1043/1043 [==============================] - 0s 454us/sample - loss: 0.6571 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.5977\n",
      "Epoch 6/30\n",
      "1043/1043 [==============================] - 0s 451us/sample - loss: 0.6411 - accuracy: 0.6002 - val_loss: 0.6503 - val_accuracy: 0.6169\n",
      "Epoch 7/30\n",
      "1043/1043 [==============================] - 1s 525us/sample - loss: 0.6277 - accuracy: 0.6002 - val_loss: 0.6439 - val_accuracy: 0.6207\n",
      "Epoch 8/30\n",
      "1043/1043 [==============================] - 0s 406us/sample - loss: 0.6119 - accuracy: 0.6059 - val_loss: 0.6383 - val_accuracy: 0.6322\n",
      "Epoch 9/30\n",
      "1043/1043 [==============================] - 0s 399us/sample - loss: 0.5982 - accuracy: 0.6318 - val_loss: 0.6341 - val_accuracy: 0.6437\n",
      "Epoch 10/30\n",
      "1043/1043 [==============================] - 0s 477us/sample - loss: 0.5838 - accuracy: 0.6309 - val_loss: 0.6274 - val_accuracy: 0.6398\n",
      "Epoch 11/30\n",
      "1043/1043 [==============================] - 0s 425us/sample - loss: 0.5695 - accuracy: 0.6798 - val_loss: 0.6212 - val_accuracy: 0.6437\n",
      "Epoch 12/30\n",
      "1043/1043 [==============================] - 0s 439us/sample - loss: 0.5545 - accuracy: 0.6539 - val_loss: 0.6168 - val_accuracy: 0.6590\n",
      "Epoch 13/30\n",
      "1043/1043 [==============================] - 0s 428us/sample - loss: 0.5384 - accuracy: 0.6884 - val_loss: 0.6102 - val_accuracy: 0.6590\n",
      "Epoch 14/30\n",
      "1043/1043 [==============================] - 1s 509us/sample - loss: 0.5234 - accuracy: 0.6913 - val_loss: 0.6071 - val_accuracy: 0.6897\n",
      "Epoch 15/30\n",
      "1043/1043 [==============================] - 0s 412us/sample - loss: 0.5077 - accuracy: 0.7239 - val_loss: 0.5993 - val_accuracy: 0.6743\n",
      "Epoch 16/30\n",
      "1043/1043 [==============================] - 0s 401us/sample - loss: 0.4902 - accuracy: 0.7210 - val_loss: 0.5951 - val_accuracy: 0.7011\n",
      "Epoch 17/30\n",
      "1043/1043 [==============================] - 0s 397us/sample - loss: 0.4733 - accuracy: 0.7641 - val_loss: 0.5895 - val_accuracy: 0.6858\n",
      "Epoch 18/30\n",
      "1043/1043 [==============================] - 0s 399us/sample - loss: 0.4563 - accuracy: 0.7536 - val_loss: 0.5862 - val_accuracy: 0.6935\n",
      "Epoch 19/30\n",
      "1043/1043 [==============================] - 0s 384us/sample - loss: 0.4390 - accuracy: 0.7689 - val_loss: 0.5792 - val_accuracy: 0.6973\n",
      "Epoch 20/30\n",
      "1043/1043 [==============================] - 0s 428us/sample - loss: 0.4217 - accuracy: 0.8006 - val_loss: 0.5750 - val_accuracy: 0.7011\n",
      "Epoch 21/30\n",
      "1043/1043 [==============================] - 0s 424us/sample - loss: 0.4010 - accuracy: 0.8082 - val_loss: 0.5699 - val_accuracy: 0.7126\n",
      "Epoch 22/30\n",
      "1043/1043 [==============================] - 0s 390us/sample - loss: 0.3813 - accuracy: 0.8169 - val_loss: 0.5670 - val_accuracy: 0.7126\n",
      "Epoch 23/30\n",
      "1043/1043 [==============================] - 0s 391us/sample - loss: 0.3641 - accuracy: 0.8504 - val_loss: 0.5639 - val_accuracy: 0.7011\n",
      "Epoch 24/30\n",
      "1043/1043 [==============================] - 0s 391us/sample - loss: 0.3452 - accuracy: 0.8332 - val_loss: 0.5666 - val_accuracy: 0.7165\n",
      "Epoch 25/30\n",
      "1043/1043 [==============================] - 0s 389us/sample - loss: 0.3270 - accuracy: 0.8686 - val_loss: 0.5585 - val_accuracy: 0.7241\n",
      "Epoch 26/30\n",
      "1043/1043 [==============================] - 0s 397us/sample - loss: 0.3080 - accuracy: 0.8811 - val_loss: 0.5578 - val_accuracy: 0.7318\n",
      "Epoch 27/30\n",
      "1043/1043 [==============================] - 0s 400us/sample - loss: 0.2875 - accuracy: 0.8917 - val_loss: 0.5540 - val_accuracy: 0.7356\n",
      "Epoch 28/30\n",
      "1043/1043 [==============================] - 0s 396us/sample - loss: 0.2634 - accuracy: 0.8974 - val_loss: 0.5650 - val_accuracy: 0.7280\n",
      "Epoch 29/30\n",
      "1043/1043 [==============================] - 1s 485us/sample - loss: 0.2401 - accuracy: 0.9089 - val_loss: 0.5724 - val_accuracy: 0.7165\n",
      "Epoch 30/30\n",
      "1043/1043 [==============================] - 0s 403us/sample - loss: 0.2190 - accuracy: 0.9243 - val_loss: 0.5720 - val_accuracy: 0.7318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       150\n",
      "           1       0.73      0.59      0.65       111\n",
      "\n",
      "    accuracy                           0.73       261\n",
      "   macro avg       0.73      0.71      0.72       261\n",
      "weighted avg       0.73      0.73      0.73       261\n",
      "\n",
      "[[125  25]\n",
      " [ 45  66]]\n"
     ]
    }
   ],
   "source": [
    "#model architecture. Largely taken from TensorFlow documentation, further hyperparameter tuning will be needed\n",
    "\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "#first, fit the model to the CAD data\n",
    "\n",
    "model.fit(X_train_C, y_train_C,\n",
    "          batch_size=50,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_C, y_test_C))\n",
    "\n",
    "#get classification report to further analyze the model performance\n",
    "pred = model.predict(X_test_C)\n",
    "preds = np.where(pred > .5, 1, 0)\n",
    "\n",
    "print(classification_report(y_test_C, preds, digits=2))\n",
    "print(confusion_matrix(y_test_C, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 535 samples, validate on 134 samples\n",
      "Epoch 1/70\n",
      "535/535 [==============================] - 1s 2ms/sample - loss: 2.6770 - accuracy: 0.4785 - val_loss: 1.8040 - val_accuracy: 0.4925\n",
      "Epoch 2/70\n",
      "535/535 [==============================] - 0s 558us/sample - loss: 1.5929 - accuracy: 0.4841 - val_loss: 1.1912 - val_accuracy: 0.5448\n",
      "Epoch 3/70\n",
      "535/535 [==============================] - 0s 669us/sample - loss: 1.0878 - accuracy: 0.5364 - val_loss: 0.9952 - val_accuracy: 0.5746\n",
      "Epoch 4/70\n",
      "535/535 [==============================] - 0s 630us/sample - loss: 0.9562 - accuracy: 0.5477 - val_loss: 0.9213 - val_accuracy: 0.5597\n",
      "Epoch 5/70\n",
      "535/535 [==============================] - 0s 454us/sample - loss: 0.8733 - accuracy: 0.5458 - val_loss: 0.8423 - val_accuracy: 0.5597\n",
      "Epoch 6/70\n",
      "535/535 [==============================] - 0s 460us/sample - loss: 0.8000 - accuracy: 0.5589 - val_loss: 0.7998 - val_accuracy: 0.5373\n",
      "Epoch 7/70\n",
      "535/535 [==============================] - 0s 507us/sample - loss: 0.7637 - accuracy: 0.5682 - val_loss: 0.7810 - val_accuracy: 0.5149\n",
      "Epoch 8/70\n",
      "535/535 [==============================] - 0s 529us/sample - loss: 0.7377 - accuracy: 0.5757 - val_loss: 0.7675 - val_accuracy: 0.5299\n",
      "Epoch 9/70\n",
      "535/535 [==============================] - 0s 500us/sample - loss: 0.7119 - accuracy: 0.5907 - val_loss: 0.7585 - val_accuracy: 0.5448\n",
      "Epoch 10/70\n",
      "535/535 [==============================] - 0s 533us/sample - loss: 0.6870 - accuracy: 0.6075 - val_loss: 0.7498 - val_accuracy: 0.5522\n",
      "Epoch 11/70\n",
      "535/535 [==============================] - 0s 540us/sample - loss: 0.6634 - accuracy: 0.6187 - val_loss: 0.7434 - val_accuracy: 0.5597\n",
      "Epoch 12/70\n",
      "535/535 [==============================] - 0s 665us/sample - loss: 0.6420 - accuracy: 0.6336 - val_loss: 0.7355 - val_accuracy: 0.5672\n",
      "Epoch 13/70\n",
      "535/535 [==============================] - 0s 524us/sample - loss: 0.6229 - accuracy: 0.6430 - val_loss: 0.7313 - val_accuracy: 0.5448\n",
      "Epoch 14/70\n",
      "535/535 [==============================] - 0s 468us/sample - loss: 0.6057 - accuracy: 0.6617 - val_loss: 0.7295 - val_accuracy: 0.5672\n",
      "Epoch 15/70\n",
      "535/535 [==============================] - 0s 509us/sample - loss: 0.5863 - accuracy: 0.6710 - val_loss: 0.7243 - val_accuracy: 0.5522\n",
      "Epoch 16/70\n",
      "535/535 [==============================] - 0s 512us/sample - loss: 0.5707 - accuracy: 0.6785 - val_loss: 0.7222 - val_accuracy: 0.5522\n",
      "Epoch 17/70\n",
      "535/535 [==============================] - 0s 688us/sample - loss: 0.5561 - accuracy: 0.7103 - val_loss: 0.7208 - val_accuracy: 0.5597\n",
      "Epoch 18/70\n",
      "535/535 [==============================] - 0s 649us/sample - loss: 0.5412 - accuracy: 0.7159 - val_loss: 0.7165 - val_accuracy: 0.5522\n",
      "Epoch 19/70\n",
      "535/535 [==============================] - 0s 477us/sample - loss: 0.5259 - accuracy: 0.7196 - val_loss: 0.7154 - val_accuracy: 0.5597\n",
      "Epoch 20/70\n",
      "535/535 [==============================] - 0s 498us/sample - loss: 0.5124 - accuracy: 0.7234 - val_loss: 0.7123 - val_accuracy: 0.5597\n",
      "Epoch 21/70\n",
      "535/535 [==============================] - 0s 525us/sample - loss: 0.5005 - accuracy: 0.7570 - val_loss: 0.7095 - val_accuracy: 0.5522\n",
      "Epoch 22/70\n",
      "535/535 [==============================] - 0s 536us/sample - loss: 0.4866 - accuracy: 0.7626 - val_loss: 0.7098 - val_accuracy: 0.5522\n",
      "Epoch 23/70\n",
      "535/535 [==============================] - 0s 663us/sample - loss: 0.4733 - accuracy: 0.7757 - val_loss: 0.7083 - val_accuracy: 0.5448\n",
      "Epoch 24/70\n",
      "535/535 [==============================] - 0s 641us/sample - loss: 0.4598 - accuracy: 0.7963 - val_loss: 0.7068 - val_accuracy: 0.5448\n",
      "Epoch 25/70\n",
      "535/535 [==============================] - 0s 499us/sample - loss: 0.4480 - accuracy: 0.8150 - val_loss: 0.7071 - val_accuracy: 0.5448\n",
      "Epoch 26/70\n",
      "535/535 [==============================] - 0s 481us/sample - loss: 0.4348 - accuracy: 0.8206 - val_loss: 0.7047 - val_accuracy: 0.5448\n",
      "Epoch 27/70\n",
      "535/535 [==============================] - 0s 553us/sample - loss: 0.4233 - accuracy: 0.8262 - val_loss: 0.7030 - val_accuracy: 0.5522\n",
      "Epoch 28/70\n",
      "535/535 [==============================] - 0s 691us/sample - loss: 0.4102 - accuracy: 0.8374 - val_loss: 0.7026 - val_accuracy: 0.5746\n",
      "Epoch 29/70\n",
      "535/535 [==============================] - 0s 612us/sample - loss: 0.3995 - accuracy: 0.8449 - val_loss: 0.7021 - val_accuracy: 0.5746\n",
      "Epoch 30/70\n",
      "535/535 [==============================] - 0s 551us/sample - loss: 0.3871 - accuracy: 0.8617 - val_loss: 0.7017 - val_accuracy: 0.5746\n",
      "Epoch 31/70\n",
      "535/535 [==============================] - 0s 659us/sample - loss: 0.3757 - accuracy: 0.8673 - val_loss: 0.6993 - val_accuracy: 0.5746\n",
      "Epoch 32/70\n",
      "535/535 [==============================] - 0s 631us/sample - loss: 0.3663 - accuracy: 0.8804 - val_loss: 0.6993 - val_accuracy: 0.5821\n",
      "Epoch 33/70\n",
      "535/535 [==============================] - 0s 613us/sample - loss: 0.3533 - accuracy: 0.8822 - val_loss: 0.6999 - val_accuracy: 0.5970\n",
      "Epoch 34/70\n",
      "535/535 [==============================] - 0s 480us/sample - loss: 0.3425 - accuracy: 0.9009 - val_loss: 0.6991 - val_accuracy: 0.6045\n",
      "Epoch 35/70\n",
      "535/535 [==============================] - 0s 549us/sample - loss: 0.3311 - accuracy: 0.9009 - val_loss: 0.6970 - val_accuracy: 0.5896\n",
      "Epoch 36/70\n",
      "535/535 [==============================] - 0s 586us/sample - loss: 0.3206 - accuracy: 0.9103 - val_loss: 0.6971 - val_accuracy: 0.5970\n",
      "Epoch 37/70\n",
      "535/535 [==============================] - 0s 499us/sample - loss: 0.3108 - accuracy: 0.9252 - val_loss: 0.6977 - val_accuracy: 0.6119\n",
      "Epoch 38/70\n",
      "535/535 [==============================] - 0s 532us/sample - loss: 0.3006 - accuracy: 0.9271 - val_loss: 0.6968 - val_accuracy: 0.6045\n",
      "Epoch 39/70\n",
      "535/535 [==============================] - 0s 524us/sample - loss: 0.2906 - accuracy: 0.9383 - val_loss: 0.6977 - val_accuracy: 0.6045\n",
      "Epoch 40/70\n",
      "535/535 [==============================] - 0s 669us/sample - loss: 0.2797 - accuracy: 0.9514 - val_loss: 0.6972 - val_accuracy: 0.6045\n",
      "Epoch 41/70\n",
      "535/535 [==============================] - 0s 518us/sample - loss: 0.2707 - accuracy: 0.9383 - val_loss: 0.6975 - val_accuracy: 0.6119\n",
      "Epoch 42/70\n",
      "535/535 [==============================] - 0s 809us/sample - loss: 0.2618 - accuracy: 0.9551 - val_loss: 0.6982 - val_accuracy: 0.6045\n",
      "Epoch 43/70\n",
      "535/535 [==============================] - 0s 537us/sample - loss: 0.2527 - accuracy: 0.9589 - val_loss: 0.6978 - val_accuracy: 0.6194\n",
      "Epoch 44/70\n",
      "535/535 [==============================] - 0s 496us/sample - loss: 0.2428 - accuracy: 0.9607 - val_loss: 0.6992 - val_accuracy: 0.5970\n",
      "Epoch 45/70\n",
      "535/535 [==============================] - 0s 509us/sample - loss: 0.2341 - accuracy: 0.9664 - val_loss: 0.6979 - val_accuracy: 0.6194\n",
      "Epoch 46/70\n",
      "535/535 [==============================] - 0s 748us/sample - loss: 0.2255 - accuracy: 0.9664 - val_loss: 0.6992 - val_accuracy: 0.6194\n",
      "Epoch 47/70\n",
      "535/535 [==============================] - 0s 778us/sample - loss: 0.2172 - accuracy: 0.9682 - val_loss: 0.7002 - val_accuracy: 0.6194\n",
      "Epoch 48/70\n",
      "535/535 [==============================] - 0s 646us/sample - loss: 0.2106 - accuracy: 0.9701 - val_loss: 0.7005 - val_accuracy: 0.6194\n",
      "Epoch 49/70\n",
      "535/535 [==============================] - 0s 492us/sample - loss: 0.2038 - accuracy: 0.9682 - val_loss: 0.7006 - val_accuracy: 0.6343\n",
      "Epoch 50/70\n",
      "535/535 [==============================] - 0s 524us/sample - loss: 0.1932 - accuracy: 0.9738 - val_loss: 0.7025 - val_accuracy: 0.6194\n",
      "Epoch 51/70\n",
      "535/535 [==============================] - 0s 509us/sample - loss: 0.1871 - accuracy: 0.9794 - val_loss: 0.7010 - val_accuracy: 0.6269\n",
      "Epoch 52/70\n",
      "535/535 [==============================] - 0s 499us/sample - loss: 0.1797 - accuracy: 0.9776 - val_loss: 0.7033 - val_accuracy: 0.6418\n",
      "Epoch 53/70\n",
      "535/535 [==============================] - 0s 542us/sample - loss: 0.1724 - accuracy: 0.9794 - val_loss: 0.7039 - val_accuracy: 0.6343\n",
      "Epoch 54/70\n",
      "535/535 [==============================] - 0s 507us/sample - loss: 0.1659 - accuracy: 0.9813 - val_loss: 0.7047 - val_accuracy: 0.6343\n",
      "Epoch 55/70\n",
      "535/535 [==============================] - 0s 504us/sample - loss: 0.1595 - accuracy: 0.9832 - val_loss: 0.7057 - val_accuracy: 0.6418\n",
      "Epoch 56/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535/535 [==============================] - 0s 499us/sample - loss: 0.1532 - accuracy: 0.9832 - val_loss: 0.7062 - val_accuracy: 0.6493\n",
      "Epoch 57/70\n",
      "535/535 [==============================] - 0s 458us/sample - loss: 0.1473 - accuracy: 0.9850 - val_loss: 0.7087 - val_accuracy: 0.6493\n",
      "Epoch 58/70\n",
      "535/535 [==============================] - 0s 507us/sample - loss: 0.1416 - accuracy: 0.9869 - val_loss: 0.7098 - val_accuracy: 0.6567\n",
      "Epoch 59/70\n",
      "535/535 [==============================] - 0s 480us/sample - loss: 0.1361 - accuracy: 0.9907 - val_loss: 0.7111 - val_accuracy: 0.6567\n",
      "Epoch 60/70\n",
      "535/535 [==============================] - 0s 556us/sample - loss: 0.1313 - accuracy: 0.9888 - val_loss: 0.7126 - val_accuracy: 0.6567\n",
      "Epoch 61/70\n",
      "535/535 [==============================] - 0s 620us/sample - loss: 0.1256 - accuracy: 0.9944 - val_loss: 0.7156 - val_accuracy: 0.6493\n",
      "Epoch 62/70\n",
      "535/535 [==============================] - 0s 647us/sample - loss: 0.1207 - accuracy: 0.9944 - val_loss: 0.7164 - val_accuracy: 0.6493\n",
      "Epoch 63/70\n",
      "535/535 [==============================] - 0s 615us/sample - loss: 0.1162 - accuracy: 0.9944 - val_loss: 0.7196 - val_accuracy: 0.6567\n",
      "Epoch 64/70\n",
      "535/535 [==============================] - 0s 648us/sample - loss: 0.1115 - accuracy: 0.9944 - val_loss: 0.7198 - val_accuracy: 0.6567\n",
      "Epoch 65/70\n",
      "535/535 [==============================] - 0s 563us/sample - loss: 0.1072 - accuracy: 0.9944 - val_loss: 0.7219 - val_accuracy: 0.6567\n",
      "Epoch 66/70\n",
      "535/535 [==============================] - 0s 637us/sample - loss: 0.1030 - accuracy: 0.9944 - val_loss: 0.7243 - val_accuracy: 0.6567\n",
      "Epoch 67/70\n",
      "535/535 [==============================] - 0s 618us/sample - loss: 0.0990 - accuracy: 0.9944 - val_loss: 0.7267 - val_accuracy: 0.6567\n",
      "Epoch 68/70\n",
      "535/535 [==============================] - 0s 564us/sample - loss: 0.0953 - accuracy: 0.9944 - val_loss: 0.7294 - val_accuracy: 0.6567\n",
      "Epoch 69/70\n",
      "535/535 [==============================] - 0s 476us/sample - loss: 0.0916 - accuracy: 0.9981 - val_loss: 0.7304 - val_accuracy: 0.6493\n",
      "Epoch 70/70\n",
      "535/535 [==============================] - 0s 628us/sample - loss: 0.0879 - accuracy: 0.9981 - val_loss: 0.7329 - val_accuracy: 0.6493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.74      0.66        62\n",
      "         1.0       0.72      0.57      0.64        72\n",
      "\n",
      "    accuracy                           0.65       134\n",
      "   macro avg       0.66      0.66      0.65       134\n",
      "weighted avg       0.66      0.65      0.65       134\n",
      "\n",
      "[[46 16]\n",
      " [31 41]]\n"
     ]
    }
   ],
   "source": [
    "#Now fit the model to the smoker data\n",
    "\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "\n",
    "model_S = tf.keras.Sequential()\n",
    "model_S.add(hub_layer)\n",
    "model_S.add(tf.keras.layers.Dense(4, activation='relu'))\n",
    "model_S.add(tf.keras.layers.Dense(1))\n",
    "model_S.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_S.fit(X_train_S, y_train_S,\n",
    "          batch_size=50,\n",
    "          epochs=70,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_S, y_test_S))\n",
    "\n",
    "#get classification report to further analyze the model performance\n",
    "pred = model_S.predict(X_test_S)\n",
    "preds = np.where(pred > .5, 1, 0)\n",
    "\n",
    "print(classification_report(y_test_S, preds, digits=2))\n",
    "print(confusion_matrix(y_test_S, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7854406130268199\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       150\n",
      "           1       0.74      0.77      0.75       111\n",
      "\n",
      "    accuracy                           0.79       261\n",
      "   macro avg       0.78      0.78      0.78       261\n",
      "weighted avg       0.79      0.79      0.79       261\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[119  31]\n",
      " [ 25  86]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "# Try Naive Bayes MultinomialNB classifier with TfidfVecorizer \n",
    "stop_words = set(stopwords.words('english')) #define the stopwords\n",
    "\n",
    "#vectorizer = TfidfVectorizer(max_df= 2.0, min_df=2, stop_words=stop_words)\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words=stop_words)\n",
    "\n",
    "X_C = vectorizer.fit_transform(df_CAD['Note'])\n",
    "#y_C already defined\n",
    "\n",
    "#re-split the data\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = train_test_split(X_C, y_C, random_state=42, test_size=.2)\n",
    "\n",
    "\n",
    "clf = MultinomialNB(alpha=0)\n",
    "clf.fit(X_train_C, y_train_C)\n",
    "y_pred = clf.predict(X_test_C)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test_C, y_pred)}')\n",
    "print(f'\\nClassification report:\\n{classification_report(y_test_C, y_pred)}')\n",
    "print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test_C, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6716417910447762\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.63      0.64        62\n",
      "         1.0       0.69      0.71      0.70        72\n",
      "\n",
      "    accuracy                           0.67       134\n",
      "   macro avg       0.67      0.67      0.67       134\n",
      "weighted avg       0.67      0.67      0.67       134\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[39 23]\n",
      " [21 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "# Try the MultinomialNB on the smoker data \n",
    "\n",
    "stop_words = set(stopwords.words('english')) #define the stopwords\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df= 2.0, min_df=2, stop_words=stop_words)\n",
    "\n",
    "#vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "X_S = vectorizer.fit_transform(df_smoker['Note'])\n",
    "#y_S already defined\n",
    "\n",
    "#re-split the data\n",
    "X_train_S, X_test_S, y_train_S, y_test_S = train_test_split(X_S, y_S, random_state=42, test_size=.2)\n",
    "\n",
    "\n",
    "clf = MultinomialNB(alpha=0)\n",
    "clf.fit(X_train_S, y_train_S)\n",
    "y_pred = clf.predict(X_test_S)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test_S, y_pred)}')\n",
    "print(f'\\nClassification report:\\n{classification_report(y_test_S, y_pred)}')\n",
    "print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test_S, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
